{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nexar Challenge 2\n",
    "Re-Train it with nexar Dataset\n",
    "<img src=\"nb_images/logo-nexar.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import misc\n",
    "import argparse\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import os, sys\n",
    "import shutil\n",
    "import fnmatch\n",
    "import math\n",
    "import random, shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from yolo_utils2 import predict_any, create_model, get_batch, iou, mAP_eval \n",
    "\n",
    "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
    "from retrain_yolo import process_data,process_data_pil,get_classes,get_anchors,get_detector_mask,train,draw\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\" # importing iPython output fucntioanlity \n",
    "\n",
    "#sys.path.append(os.getcwd()+'/yad2k/models' )\n",
    "#sys.path.append(os.getcwd()+'/yad2k/utils' )\n",
    "\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body, yolo_eval\n",
    "# from yad2k.utils.draw_boxes import draw_boxes\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitons and paths\n",
    "\n",
    "# path to images and boxes\n",
    "images_dir = os.getcwd()+'/../data/Training/nexet_2017_'\n",
    "boxes_dir = os.getcwd()+'/../data/Training/train_boxes.csv'\n",
    "\n",
    "training_chunks_path = os.getcwd()+'/../data/Training/training_chunks/'\n",
    "training_data_chunks_size = 8*30 # Number of samples of  chuncked downs training data files. Need to be multiple of smallest mini-batch to be used\n",
    "training_chunks_name = 'training_chunk_'\n",
    "images_test_dir = os.getcwd()+'/../data/Test/nexet_2017_test'\n",
    "\n",
    "# anchors_path to anchors file, defaults to yolo_anchors.txt\n",
    "anchors_path = \"model_data/yolo_anchors.txt\"\n",
    "\n",
    "image_shape = (720., 1280.)\n",
    "\n",
    "# Default anchor boxes\n",
    "YOLO_ANCHORS = np.array(\n",
    "    ((0.57273, 0.677385), (1.87446, 2.06253), (3.33843, 5.47434),\n",
    "     (7.88282, 3.52778), (9.77052, 9.16828)))\n",
    "\n",
    "# path to classes file, defaults to pascal_classes.txt\n",
    "# Nexar classes ->\n",
    "class_idx= {\"car\":0,\"bus\":1,\"pickup_truck\":2,\"truck\":3,\"van\":4}\n",
    "classes_path = \"model_data/nexar_classes.txt\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Preparing the data\n",
    "\n",
    "\n",
    "To perform training we need:\n",
    "* class_names,     anchors,      image_data,      boxes,     detectors_mask,      matching_true_boxes\n",
    "\n",
    "Put the training data into a format: Data['class_names'], etc\n",
    "\n",
    "We will load the original data, process it and save it into several npz (Data-chuncks) to perform mini-batches training.\n",
    "\n",
    "Normal batches sizes are 8 and 32 samples, so we will make sure our data npz (Data-chuncks) are multiple of 8: 160 samples per chunk\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anchors and classes names\n",
    "class_names = get_classes(classes_path)\n",
    "anchors = get_anchors(anchors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Dataset folder 1\n",
      "Processing Dataset folder 2\n",
      "Processing Dataset folder 3\n"
     ]
    }
   ],
   "source": [
    "dts_images_names = []\n",
    "for dts in range(1,4):\n",
    "    print(\"Processing Dataset folder\", dts)\n",
    "    dts_files = os.listdir(images_dir+str(dts)) # files in dataset dts\n",
    "    for i,image_sample in enumerate(dts_files): #for all images in the dataset folder\n",
    "        dts_files[i] = images_dir+str(dts)+\"/\"+image_sample\n",
    "    random.shuffle(dts_files) # Shuffle the order of data-chunks: Try to avoid biases\n",
    "    dts_images_names.extend(dts_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     32
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chunk number  1\n",
      "     Chunked boxes data dimensions: (240, 10, 5)\n",
      "     Chunked image data dimensions: (240, 416, 416, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'anchors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4031a5162aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmatching_true_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdetectors_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching_true_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_true_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mdetectors_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetectors_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anchors' is not defined"
     ]
    }
   ],
   "source": [
    "# Custom dataset object \n",
    "images_list = []\n",
    "boxes_list = []\n",
    "\n",
    "# Load the train boxes\n",
    "Img_db = pd.read_csv(boxes_dir, header = 0)\n",
    "\n",
    "samples_to_chunk = 0\n",
    "chunk_count = 1\n",
    "\n",
    "random.shuffle(dts_images_names) # Shuffle the order of data-chunks: Try to avoid biases\n",
    "\n",
    "for image_sample in dts_images_names: #for all images in the dataset folder\n",
    "#     print(image_sample.split(\"/\")[-1])\n",
    "\n",
    "    ## Get original Images and Boxes\n",
    "    # Get the image\n",
    "    img2 = mpimg.imread(image_sample)\n",
    "    images_list.append(img2)\n",
    "    \n",
    "    # Write the labels and boxes\n",
    "    labels_boxes = []\n",
    "#     print(Img_db[Img_db['image_filename']==image_sample.split(\"/\")[-1]].as_matrix())\n",
    "    for box_matched in Img_db[Img_db['image_filename']==image_sample.split(\"/\")[-1]].as_matrix():\n",
    "        labels_boxes.append( [class_idx[box_matched[-2]], *box_matched[2:6]] )\n",
    "    boxes_list.append(np.asarray(labels_boxes))\n",
    "\n",
    "    samples_to_chunk +=1\n",
    "\n",
    "    ## Translate to training model's inputs\n",
    "    if(samples_to_chunk >= training_data_chunks_size or image_sample == dts_images_names[-1]):\n",
    "        print(' Chunk number ',str(chunk_count))\n",
    "        ### Preprocess the data: get images and boxes\n",
    "        # get images and boxes\n",
    "        image_data, boxes = process_data(images_list, boxes_list)\n",
    "        print('     Chunked boxes data dimensions:', boxes.shape)\n",
    "        image_data[0,:,:]\n",
    "        print('     Chunked image data dimensions:',image_data.shape)\n",
    "        ### Precompute detectors_mask and matching_true_boxes for training\n",
    "        # Precompute detectors_mask and matching_true_boxes for training\n",
    "        detectors_mask = [0 for i in range(len(boxes))]\n",
    "        matching_true_boxes = [0 for i in range(len(boxes))]\n",
    "        for i, box in enumerate(boxes):\n",
    "            detectors_mask[i], matching_true_boxes[i] = preprocess_true_boxes(box, anchors, [416, 416])\n",
    "\n",
    "        detectors_mask = np.array(detectors_mask)\n",
    "        matching_true_boxes = np.array(matching_true_boxes)\n",
    "\n",
    "        print(\"     detectors_mask shape     \",detectors_mask.shape)\n",
    "        print(\"     matching_true_boxes shape\",matching_true_boxes.shape)\n",
    "\n",
    "        # Save\n",
    "#         np.savez(training_chunks_path+training_chunks_name+str(chunk_count),\n",
    "#                  class_names = class_names,\n",
    "#                  anchors = anchors,\n",
    "#                  image_data = image_data,\n",
    "#                  boxes = boxes,\n",
    "#                  detectors_mask = detectors_mask,\n",
    "#                  matching_true_boxes = matching_true_boxes\n",
    "#                 )\n",
    "        chunk_count += 1\n",
    "        # Remove data from RAM and update: Our problem is low RAM\n",
    "        images_list = []\n",
    "        boxes_list = []\n",
    "        image_data = None\n",
    "        boxes = None\n",
    "\n",
    "        samples_to_chunk = 0\n",
    "        # control\n",
    "#             input(\"Press Enter to continue...\")"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OMdut",
   "launcher_item_id": "bbBOL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
